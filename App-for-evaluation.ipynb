{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8236c974-6248-424c-a89d-aaecf13f98c3",
   "metadata": {},
   "source": [
    "### Basic App for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a24daf8-35e8-4f74-ba5d-55ea3fdd3973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc74d1dc-5b16-4536-84f3-a5a49e6b8ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54fd4a9e-d4fa-47cc-8159-5321161771a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa2d9b8-f5c3-42c7-b344-1ab650c3cdff",
   "metadata": {},
   "source": [
    "**Load document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9718855f-f45c-4ea7-952f-00a5459c48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e61cd154-f8d7-46ea-8032-97fbd8f8221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('be-good-and-how-not-to-die.txt')\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0260aec-f58b-42b7-9d4f-b695560daadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Th document has 27419 characters\n"
     ]
    }
   ],
   "source": [
    "print(f\"Th document has {len(document[0].page_content)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a8f93-a270-4f7a-88be-e4fb14f4aaf3",
   "metadata": {},
   "source": [
    "**Split the document in smaller chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0271d141-d65a-4542-9c1e-bffb2cc3b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5b82039-924a-447f-b837-3e2b43560623",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 3000,\n",
    "    chunk_overlap = 400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d55516f2-c17e-4e04-b90e-884cc4921768",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_chunks = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a2c2410-6bf1-441c-9842-4b08a1575fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 12 chunks\n"
     ]
    }
   ],
   "source": [
    "print(f\"Now you have {len(documents_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32f8205b-fa68-4846-8f05-e8372a48f07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(documents_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aaa559-dccf-49cc-9d3d-0723ca8633d6",
   "metadata": {},
   "source": [
    "**Convert text chunks in numeric embeddings and load them to the vector database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6f288db-768c-4234-b482-a874df875240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02882faf-f17c-47ab-9bf0-8f2e02017b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86546f92-501e-48ab-b8d0-ac2835fe62ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82842790-5e07-41aa-8e15-8f5159b94a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_embeddings = FAISS.from_documents(documents_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e3422-4dd8-447c-ad94-6e03b22a1965",
   "metadata": {},
   "source": [
    "**Create a Retrieval Question & Answering Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f36f876-6c82-48b5-98fd-1b519d4ac4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec8075c7-30c5-4bb2-93c0-5dc3f293cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_key: Tells the chain where will the user prompt be located\n",
    "QA_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=stored_embeddings.as_retriever(),\n",
    "    input_key=\"question\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53545854-e2fa-414e-9211-fa368532857a",
   "metadata": {},
   "source": [
    "Notice that we have added input_key in the QA_chain configuration. This tells the chain where will the user prompt be located.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab69899c-3f13-4f76-a6f7-24c58a747332",
   "metadata": {},
   "source": [
    "**We are going to evaluate this app with 2 questions and answers we already know (these answers are technically known as \"ground truth answers\")**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10b7d9d2-0831-4606-830a-3b6ce2462c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_and_answers = [\n",
    "    {\n",
    "        'question' : \"Where is a whole neighborhood of YC-funded startups?\", \n",
    "        'answer' :\"In San Francisco\"},\n",
    "    {\n",
    "        'question' : \"What may be the most valuable  thing Paul Buchheit made for Google?\", \n",
    "        'answer' : \"The motto Don't be evil\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b0a7462-be0c-4b6d-a20f-d70627a8391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = QA_chain.apply(questions_and_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b6fd4dd-f81d-4829-8048-96d1602cbdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Where is a whole neighborhood of YC-funded startups?',\n",
       "  'answer': 'In San Francisco',\n",
       "  'result': ' San Francisco'},\n",
       " {'question': 'What may be the most valuable  thing Paul Buchheit made for Google?',\n",
       "  'answer': \"The motto Don't be evil\",\n",
       "  'result': ' The phrase \"Don\\'t be evil.\"'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d914fc-f055-4673-85b4-b66bbebb4bf4",
   "metadata": {},
   "source": [
    "* Question is the input query\n",
    "* Answer is the expected response\n",
    "* Result is the app's response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda7d33-4f73-4c11-b58f-2e9079550420",
   "metadata": {},
   "source": [
    "**The evaluation of this App has been positive, since the App has responded the 2 evaluation questions right.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b19d5-cd75-428a-a5c5-621fc94c391c",
   "metadata": {},
   "source": [
    "**But instead of confirming that manually ourselves, we can ask the LLM to check if the responses are coincidental with the \"ground truth answers\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fb306cb-0fc7-4e6e-915f-25af41124ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ad225a4-6871-46aa-9365-59042d51ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d4c78e8-30db-4342-9228-a63883e48833",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_responses = evaluation_chain.evaluate(\n",
    "    questions_and_answers,\n",
    "    predictions,\n",
    "    question_key=\"question\",\n",
    "    answer_key=\"answer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ccea565-31f5-46e5-b9b7-615d48a41f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'results': ' CORRECT'}, {'results': ' CORRECT'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed4f041-4087-402f-b0e5-5408fa02bd91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
